{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Downward Jump Analysis\n",
    "This script is used to analyze jumps on my stocks data and rescale them looking at the jumps on the SPX."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import norm\n",
    "\n",
    "from IPython.display import display\n",
    "pio.templates.default = \"seaborn\"\n",
    "plt.style.use('seaborn')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want to analyze data for an underlying (**META**, **TSLA**, **AAPL**) and the S&P500 index. This because option prices are available for the options on the SPX index, but they aren't for options on the stock. Thus, we will compare the jumps magnitude of the two financial objects to obtain plausible market prices for stock options.\n",
    "\n",
    "Let's start by retrieving data from Google Finance, in the data range between 20 Jan 2016 and 20 Jan 2018."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the instruments to download.\n",
    "# #tickers = ['TSLA', '^GSPC']\n",
    "stock_ticker = 'META'           # AAPL, META, TSLA, MSFT, NVDA, GOOG\n",
    "index_ticker = '^GSPC'\n",
    "\n",
    "######## FIRST TIME, THEN SAVED INTO A CSV FILE ##########\n",
    "# Take all available data from 20/01/2016 until 20/01/2018.\n",
    "start_date = datetime(2016, 1, 20)\n",
    "end_date = datetime(2018, 1, 20)\n",
    "\n",
    "# Use pandas_reader.data.DataReader to load the data.\n",
    "stock_data = yf.download(stock_ticker, start=start_date, end=end_date, auto_adjust=True)\n",
    "sp500_data = yf.download(index_ticker, start=start_date, end=end_date, auto_adjust=True)\n",
    "stock_data.to_csv(f'data/{stock_ticker}_data.csv', index=True)\n",
    "#sp500_data.to_csv(f'data/SPX_data.csv', index=True)\n",
    "\n",
    "#stock_data = pd.read_csv(f'data/{stock_ticker}_data.csv')\n",
    "#sp500_data = pd.read_csv(f'data/SPX_data.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's add the columns for returns and log returns in both dataframes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find daily returns St/St-1 and Log Returns ln(St/St-1)\n",
    "stock_data['Returns'] = stock_data['Close'] / stock_data['Close'].shift()\n",
    "stock_data['Log Returns'] = np.log(stock_data['Returns'])\n",
    "\n",
    "sp500_data['Returns'] = sp500_data['Close'] / sp500_data['Close'].shift()\n",
    "sp500_data['Log Returns'] = np.log(sp500_data['Returns'])\n",
    "\n",
    "stock_data['Returns (%)'] = (stock_data['Returns'] -1) * 100\n",
    "sp500_data['Returns (%)'] = (sp500_data['Returns'] -1) * 100\n",
    "\n",
    "# Show the first rows for the stock data\n",
    "stock_data.head(6)\n",
    "\n",
    "# Show the first rows for the sp500 data\n",
    "sp500_data.head(9)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stock price evolution with RangeSlider and Selectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# VISUALIZE STOCK PRICE OVER THE YEARS\n",
    "fig = px.line(stock_data, x=stock_data.index, y = 'Close', title=f'{stock_ticker} stock price with Selectors')\n",
    "\n",
    "# Add the selectors\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = go.Figure(data=\n",
    "    [go.Candlestick(x=stock_data.index,\n",
    "                    open=stock_data[\"Open\"],\n",
    "                    high=stock_data[\"High\"],\n",
    "                    low=stock_data[\"Low\"],\n",
    "                    close=stock_data[\"Close\"])]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"{stock_ticker}'s adjusted stock price\",\n",
    "    yaxis_title=\"Price ($)\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=stock_data.index,\n",
    "    y=stock_data['Returns'],\n",
    "    mode='lines',\n",
    "    name='Stock Returns'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'{stock_ticker} Returns',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Returns',\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 1. Set a threshold\n",
    "We say that JUMPS are all returns worth less than a set threshold (here: 5%)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "threshold = 0.95\n",
    "stock_jumps = stock_data[stock_data['Returns'] < threshold].copy()\n",
    "print(f'Days with less than {- (100 - threshold*100)}% returns:\\n {stock_jumps}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=stock_data.index,\n",
    "    y=stock_data['Log Returns'],\n",
    "    mode='lines',\n",
    "    name='Stock Returns'\n",
    "))\n",
    "\n",
    "# Add the horizontal line\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=0, x1=1,\n",
    "    y0=np.log(threshold), y1=np.log(threshold),\n",
    "    xref='paper',\n",
    "    yref='y',\n",
    "    line=dict(color='red', width=2),\n",
    "    name='5% jumps threshold '\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'{stock_ticker} Log Returns',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Returns',\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's show returns for the SP500 index."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=sp500_data.index,\n",
    "    y=sp500_data['Returns'],\n",
    "    mode='lines',\n",
    "    name='Stock Returns'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'{index_ticker} Returns',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Returns',\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we filter the S&P500 data in the selected jump days"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sp500_jumps = sp500_data[sp500_data.index.isin(stock_jumps.index)]\n",
    "print(sp500_jumps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and create a separate dataframe where **Returns** and **Log returns** of both stock and index (in the selected jump days) are stored."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joined_jumps = stock_jumps[['Returns (%)']].join(sp500_jumps[['Returns (%)']], lsuffix=f'_{stock_ticker}', rsuffix='_SP500')\n",
    "print(joined_jumps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Let's analyze days in which we found jumps and compare the behaviour of the index wrt the stock.*\n",
    "The following plot contains the Close prices for both objects, highlighting the days when jumps have been observed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "highlight_dates = joined_jumps.index.tolist()\n",
    "\n",
    "start_date = datetime(2016, 1, 20)\n",
    "end_date = datetime(2018, 1, 20)\n",
    "\n",
    "resized_stock_df = stock_data.loc[start_date:end_date]\n",
    "resized_sp500_df = sp500_data.loc[start_date:end_date]\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add STOCK data to the figure\n",
    "fig.add_trace(go.Scatter(x=resized_stock_df.index, y=resized_stock_df['Close'], name=stock_ticker))\n",
    "\n",
    "# Add S&P 500 index data to the figure\n",
    "fig.add_trace(go.Scatter(x=resized_sp500_df.index, y=resized_sp500_df['Close'], name=index_ticker, yaxis='y2'))\n",
    "\n",
    "# Set the layout with the secondary y-axis\n",
    "fig.update_layout(\n",
    "    title=f'Comparison: {stock_ticker} vs S&P 500 Index',\n",
    "    xaxis_title='Date',\n",
    "    yaxis=dict(\n",
    "        title='TSLA Price',\n",
    "        anchor='free',\n",
    "        side='left',\n",
    "        position=0.05\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='S&P 500 Price',\n",
    "        overlaying='y',\n",
    "        anchor='x',\n",
    "        side='right',\n",
    "        position=0.95\n",
    "    ),\n",
    "    legend_title='Symbol',\n",
    ")\n",
    "\n",
    "# Highlight the specific days\n",
    "for date in highlight_dates:\n",
    "    fig.add_annotation(\n",
    "        x=date, y=resized_stock_df.loc[date, 'Close'],\n",
    "        showarrow=True,\n",
    "        arrowhead=1,\n",
    "        arrowsize=1.5,\n",
    "        arrowwidth=2,\n",
    "        arrowcolor='red',\n",
    "        ax=20,\n",
    "        ay=-40,\n",
    "        xanchor='center',\n",
    "        font=dict(color='red')\n",
    "    )\n",
    "\n",
    "# Display the figure\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add STOCK data to the figure\n",
    "fig.add_trace(go.Scatter(x=resized_stock_df.index, y=resized_stock_df['Returns'], name=stock_ticker))\n",
    "\n",
    "# Add S&P 500 index data to the figure\n",
    "fig.add_trace(go.Scatter(x=resized_sp500_df.index, y=resized_sp500_df['Returns'], name=index_ticker))\n",
    "\n",
    "# Set the layout with the secondary y-axis\n",
    "fig.update_layout(\n",
    "    title=f'Comparison: {stock_ticker} vs S&P 500 Index',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Returns',\n",
    "    legend=dict(\n",
    "        title='Symbol',\n",
    "        x=1,\n",
    "        y=1,\n",
    "        traceorder='normal',\n",
    "        font=dict(size=12),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Highlight the specific days\n",
    "for date in highlight_dates:\n",
    "    fig.add_annotation(\n",
    "        x=date, y=resized_stock_df.loc[date, 'Returns'],\n",
    "        showarrow=True,\n",
    "        arrowhead=1,\n",
    "        arrowsize=1.5,\n",
    "        arrowwidth=2,\n",
    "        arrowcolor='red',\n",
    "        ax=20,\n",
    "        ay=-40,\n",
    "        xanchor='center',\n",
    "        font=dict(color='red')\n",
    "    )\n",
    "\n",
    "# Display the figure\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By doing so, let's find the distance (difference of returns) between the stock returns and the SP500 returns in the selected days."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joined_jumps['Distance'] = joined_jumps[f'Returns (%)_{stock_ticker}'] / joined_jumps['Returns (%)_SP500']\n",
    "\n",
    "avg_distance = round(joined_jumps['Distance'].mean(), 4)\n",
    "\n",
    "print(f'Average scale factor: {avg_distance}' )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## METHOD 2. 99-th percentile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the 99th percentile\n",
    "threshold = np.nanpercentile(stock_data['Returns (%)'].values, 1)\n",
    "\n",
    "# Filter the returns above the threshold\n",
    "stock_jumps2 = stock_data[stock_data['Returns (%)'] < threshold]\n",
    "\n",
    "# Plot the distribution of returns\n",
    "# Create a histogram trace for all returns\n",
    "hist_trace_all = go.Histogram(x=stock_data['Returns (%)'], nbinsx=30, opacity=0.5, name='All Returns')\n",
    "\n",
    "# Create a histogram trace for low returns\n",
    "hist_trace_low = go.Histogram(x=stock_jumps2['Returns (%)'], nbinsx=30, opacity=0.9, name='Low Returns')\n",
    "\n",
    "# Create the layout\n",
    "layout = go.Layout(\n",
    "    title='Distribution of Returns',\n",
    "    xaxis=dict(title='Returns in (%)'),\n",
    "    yaxis=dict(title='Frequency'),\n",
    "    barmode='overlay'\n",
    ")\n",
    "\n",
    "# Create the figure\n",
    "figure = go.Figure(data=[hist_trace_all, hist_trace_low], layout=layout)\n",
    "\n",
    "# Display the histogram\n",
    "figure.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(threshold)\n",
    "print(stock_jumps2.shape, stock_jumps2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'99-th percentile of returns distribution: moves bigger than {round(threshold, 2)} % are jumps.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code snippet below gets the current stock ticker and show its weight in the SP500 index."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# yf.pdr_override()\n",
    "# start_date = \"2020-01-01\"\n",
    "# end_date = \"2023-01-31\"\n",
    "#\n",
    "# # Fetch S&P 500 data from Yahoo Finance\n",
    "# sp500_data = pdr.get_data_yahoo(index_ticker, start=start_date, end=end_date)\n",
    "# reference_date = '2021-05-23'  # Choose a specific date in 2016\n",
    "#\n",
    "# # Retrieve the market capitalization data for each constituent company\n",
    "# market_cap_data = pdr.get_data_yahoo(index_ticker, start=reference_date, end=reference_date)\n",
    "#\n",
    "# # Normalize the market capitalization to obtain the weights\n",
    "# sp500_weights = market_cap_data['MarketCap'] / market_cap_data['MarketCap'].sum()\n",
    "#\n",
    "# # Sort the companies by weight in descending order\n",
    "# sp500_weights = sp500_weights.sort_values(ascending=False)\n",
    "#\n",
    "# # Display the list of companies with their weights\n",
    "# print(sp500_weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Join jumps pf STOCK and INDEX in a table\n",
    "sp500_jumps2 = sp500_data[sp500_data.index.isin(stock_jumps2.index)]\n",
    "print(sp500_jumps2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joined_jumps2 = stock_jumps2[['Returns (%)']].join(sp500_jumps2[['Returns (%)']],\n",
    "                                                            lsuffix=f'_{stock_ticker}', rsuffix='_SP500')\n",
    "print(joined_jumps2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's find the average distance between jumps in stock price and jumps in index value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joined_jumps2['Distance'] = joined_jumps2[f'Returns (%)_{stock_ticker}'] / joined_jumps2[f'Returns (%)_SP500']\n",
    "\n",
    "avg_distance2 = round(joined_jumps2['Distance'].mean(), 4)\n",
    "\n",
    "print(f'Average scale factor: {avg_distance2}' )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 3. Perform a normality test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.histogram(stock_data['Log Returns'], x=stock_data['Log Returns'], nbins=30)\n",
    "mean = stock_data['Log Returns'].mean()\n",
    "std = stock_data['Log Returns'].std()\n",
    "x = np.linspace(stock_data['Log Returns'].min(), stock_data['Log Returns'].max())\n",
    "y = norm.pdf(x, mean, std)\n",
    "\n",
    "y = (1 / (std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='Normal Distribution'))\n",
    "\n",
    "fig.update_layout(title='Histogram of Log Returns',\n",
    "                  xaxis_title='Returns (%)',\n",
    "                  yaxis_title='Frequency')\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform Shapiro-Wilk normality test on STOCK Log Returns\n",
    "res_test = shapiro(stock_data['Log Returns'].dropna())\n",
    "\n",
    "print(f'Shapiro-Wilk Test - Log Returns_{stock_ticker}')\n",
    "print(\"Statistic:\", res_test.statistic)\n",
    "print('P-value:', res_test.pvalue)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the p-value is less than the conventional significance level of 0.05 (or 5%), we have sufficient evidence to reject the null hypothesis that the data follows a normal distribution. The **Shapiro-Wilk test** statistic indicates how data distribution departures from normality. A value closer to 1 suggests that the data closely follows a normal distribution, whereas a value closer to 0 suggests a significant deviation from normality.\n",
    "Due to these reasons, we will remove extreme jumps in order to make the **LOG RETURNS** column pass the normality test."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stock_returns_sorted= stock_data[['Returns', 'Log Returns', 'Returns (%)']].dropna().sort_values('Log Returns')\n",
    "\n",
    "print('Original dimensions stock dataframe: ', stock_returns_sorted.shape)\n",
    "# print(stock_returns_sorted.head(5),'\\n', stock_returns_sorted.tail(5))\n",
    "\n",
    "# Remove rows affecting the normality of the Log Returns distribution\n",
    "downward_jumps = stock_returns_sorted[:15]\n",
    "upward_jumps = stock_returns_sorted[-14:]\n",
    "stock_returns_sorted.drop(downward_jumps.index, inplace=True)\n",
    "stock_returns_sorted.drop(upward_jumps.index, inplace=True)\n",
    "print(downward_jumps)\n",
    "print(upward_jumps)\n",
    "print(stock_returns_sorted.head(10), '\\n', stock_returns_sorted.tail(10))\n",
    "print('Final dimensions stock dataframe: ', stock_returns_sorted.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform Shapiro-Wilk normality test on STOCK Log Returns\n",
    "res_test = shapiro(stock_returns_sorted['Log Returns'])\n",
    "\n",
    "print(f'Shapiro-Wilk Test - Log Returns_{stock_ticker}')\n",
    "print(\"Statistic:\", res_test.statistic)\n",
    "print('P-value:', res_test.pvalue)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### NOTE SUL SHAPIRO-WILK TEST DI NORMALITà (su META)\n",
    "Togliere valori upward e downward simultaneamente (stesso numero, di pari passo) non dà ottimi risultati, perchè: ad esempio con -16 e -9 ho un pvalue di 0.04598 mentre con -16 e -10 ho un pvalue più basso di 0.0379. Quindi bisogna insistere sul togliere salti downward più che upward. Infatti se notiamo, i salti verso l'alto, a partire dal settimo in poi, non sono superiori al 3%. Invece quelli verso il basso sono inferiori al 3% a partire dal 12esimo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### META:\n",
    "pvalue \"ottimo\" = 0.0497 (not so good) per #downward jumps = 17, #upward jumps = 9. Questo ci porta ad accettare l'ipotesi nulla che i dati siano distribuiti secondo una normale e facciamo un'analisi di distanza sui downward jumps così ottenuti.\n",
    "### TESLA:\n",
    "pvalue ottimo = 0.0862 best values to remove are #downward jumps = 5, #upward jumps = 1\n",
    "### AAPL:\n",
    "pvalue ottimo = 0.020 (molto basso, possiamo imporre un significance level $\\alpha = 0.02$) ma poi se tolgo altro la situa peggiora.\n",
    "Trovato con #downward jumps = 15, #upward jumps = 14"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.histogram(stock_returns_sorted['Log Returns'], x='Log Returns', nbins=30)\n",
    "mean = stock_returns_sorted['Log Returns'].mean()\n",
    "std = stock_returns_sorted['Log Returns'].std()\n",
    "x = np.linspace(stock_returns_sorted['Log Returns'].min(), stock_returns_sorted['Log Returns'].max(), 100)\n",
    "y = (1 / (std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='Normal Distribution'))\n",
    "\n",
    "fig.update_layout(title=f'{stock_ticker} Log Returns after high-valued jumps cleaning',\n",
    "                  xaxis_title='Log Returns',\n",
    "                  yaxis_title='Frequency')\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter the S&P data according do the just found downward jumps and then join the two dataframes finally, find the distance between the performances of stock and index."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter s&p data to find jumps\n",
    "sp500_jumps3 = sp500_data[sp500_data.index.isin(downward_jumps.index)]\n",
    "\n",
    "# Join dataframes\n",
    "joined_jumps3 = downward_jumps[['Returns', 'Log Returns', 'Returns (%)']].join(sp500_jumps3[['Returns', 'Log Returns', 'Returns (%)']],\n",
    "                                                            lsuffix=f'_{stock_ticker}', rsuffix='_SP500')\n",
    "\n",
    "print(joined_jumps3)\n",
    "\n",
    "# Find average scale factor\n",
    "joined_jumps3['Distance'] = joined_jumps3[f'Returns (%)_{stock_ticker}'] / joined_jumps3[f'Returns (%)_SP500']\n",
    "\n",
    "avg_distance3 = round(joined_jumps3['Distance'].mean(), 4)\n",
    "\n",
    "print(f'Average scale factor: {avg_distance3}' )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Average {stock_ticker} - SP500 jumps distance for the three different methods:')\n",
    "print(f'> Fixed threshold: {avg_distance}\\n> 99th percentile: {avg_distance2}\\n> Normality test: {avg_distance3}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### OPPURE: calcolo la media dei salti nello stock, la media dei salti nell'S&P e poi faccio il rapporto"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# METODO 1\n",
    "avg_stock_jumps = joined_jumps[f'Returns (%)_{stock_ticker}'].mean()\n",
    "avg_spx_jumps = joined_jumps[f'Returns (%)_SP500'].mean()\n",
    "scale_factor1 = avg_stock_jumps / avg_spx_jumps\n",
    "\n",
    "# METODO 2\n",
    "avg_stock_jumps = joined_jumps2[f'Returns (%)_{stock_ticker}'].mean()\n",
    "avg_spx_jumps = joined_jumps2[f'Returns (%)_SP500'].mean()\n",
    "scale_factor2 = avg_stock_jumps / avg_spx_jumps\n",
    "\n",
    "# METODO 3\n",
    "avg_stock_jumps = joined_jumps3[f'Returns (%)_{stock_ticker}'].mean()\n",
    "avg_spx_jumps = joined_jumps3[f'Returns (%)_SP500'].mean()\n",
    "scale_factor3 = avg_stock_jumps / avg_spx_jumps\n",
    "\n",
    "print(f'> Fixed threshold: {scale_factor1}\\n> 99th percentile: {scale_factor2}\\n> Normality test: {scale_factor3}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The scale factor obtained with the normality test is the one used to multiply the option prices, to find the prices for stock options."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale_factors = {\n",
    "    'TSLA': 10.35,\n",
    "    'META': 6.23,\n",
    "    'AAPL': 7.84\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
